---
title: "final project team 5"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
date: "`r Sys.Date()`"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(ggplot2)
library(ezids)
library(dplyr)
library(readr)
library(tidyr)
library(knitr)
library(magrittr)

df_2016<-data.frame(read.csv("Arrests 2016 Public.csv"))
df_2017<-data.frame(read.csv("Arrests 2017 Public.csv"))
df_2018<-data.frame(read.csv("Arrests by Year, 2018.csv"))
df_2019<-data.frame(read.csv("Arrests by Year, 2019.csv"))
df_2020<-data.frame(read.csv("Arrests by Year 2020.csv"))
df_2021<-data.frame(read.csv("2021 Adult Arrests.csv"))

# convert format
df_2018$Arrest.Date <- as.Date(df_2018$Arrest.Date, format = "%m/%d/%Y") %>% format()
df_2019$Arrest.Date <- as.Date(df_2019$Arrest.Date, format = "%m/%d/%Y") %>% format()
df_2020$Arrest.Date <- as.Date(df_2020$Arrest.Date, format = "%m/%d/%Y") %>% format()
df_2021$Arrest.Date <- as.Date(df_2021$Arrest.Date, format = "%Y/%m/%d") %>% format()

#bind df_2016 and df_2017, and delete some columns
df_16_17 <- rbind(df_2016, df_2017)[,-c(5,6,15,17:21,23:26)]
names(df_16_17)[c(13,14)] <- c('Arrest.Location.District','Offense.Location.District')   #rename columns

#bind df_2018 - df_2021, and delete some columns
df_18_21 <- rbind(df_2018, df_2019, df_2020, df_2021)[,-c(5,6,15,17:21,23:26)] 

DF<-rbind(df_16_17,df_18_21)

# remove abnormalities
DF <- DF[!DF$Age>=100,]

# replace dots with underscore for clarity sake, i think..
names(DF) = gsub("[.]", "_", names(DF))

# most likely "UNK" is the same as "Unknown", so we can change this
DF$Defendant_Race[DF$Defendant_Race == 'UNK'] <- 'UNKNOWN'
#unique(DF$Defendant_Race) - check that it changed

#same issue, "unk" is very likely "unknown", so change it.
DF$Defendant_Sex[DF$Defendant_Sex == 'UNK'] <- 'UNKNOWN'
#unique(DF$Defendant_Sex) - check that it changed

# Arrest category -  4 different types of Fraud & Financial crimes , 3 types of Release Violations/Fugitive -- group them into one.

DF$Arrest_Category = gsub("Fraud and Financial Crimes.*","Fraud and Financial Crimes", DF$Arrest_Category)

DF$Arrest_Category = gsub("Release Violations/Fugitive.*","Release Violations/Fugitive",DF$Arrest_Category)

#get month and day variables.. might be interesting, who knows?
DF <- separate(DF, col = Arrest_Date, into = c("Year","Month","Day"), sep = "-", remove = FALSE, fill="left")
#remove the new year column formed, it is redundant.. we already have Year column
DF = DF[,-4]

library(lubridate)
# Factorize some variables
DF$Arrest_Year = as.factor(DF$Arrest_Year)
DF$Month = as.factor(DF$Month)
DF$Day = as.factor(DF$Day)
DF$Defendant_Race = as.factor(DF$Defendant_Race)
DF$Defendant_Sex = as.factor(DF$Defendant_Sex)
DF$Arrest_Location_District = as.factor(DF$Arrest_Location_District)
DF$Offense_Location_District = as.factor(DF$Offense_Location_District)
# convert to date format
DF$Arrest_Date = as.Date(DF$Arrest_Date)
# Day format
DF$Day = day(DF$Arrest_Date)
# i want to create a week-day variable
DF$Weekday = weekdays(DF$Arrest_Date)
DF$Weekday = factor(DF$Weekday, levels = as.character(wday(c(2:7,1), label=TRUE, abbr=FALSE)))

# convert crime types to factors
DF$Arrest_Category = as.factor(DF$Arrest_Category)

DF_WM <- subset(DF, subset = Defendant_Race=='WHITE' & Defendant_Sex=='MALE')

```


```{r}
# create dataframe having "Category", "Month", "District", "Year", and "Count" as its column
DF_WM2 <- DF_WM
DF_WM2$Count <- c(rep(1,nrow(DF_WM2)))

DF_WM2 = aggregate(x=DF_WM2[c("Count")], 
                   by=list(DF_WM2$Arrest_Category, DF_WM2$Month,
                           DF_WM2$Offense_Location_District, DF_WM2$Arrest_Year),
                   sum)

colnames(DF_WM2)[1:4] = c("Category", "Month", "District", "Year")
DF_WM2 %>% subset(., District != '#N/A') %>% subset(., District != 'Unk') %>% subset(., District != 'UNKNOWN') -> DF_WM2
```

```{r}
# create a data frame with "District", "Weekend", and "Count" as columns for the specified crime.

createDF <- function(df, cat, y){
  df_temp = subset(df, Category==cat & Year==y, select=c(District, Month, Count))
  M <- c('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12')
  D <- c('1D','2D','3D','4D','5D','6D','7D' )
  for(m in M){
    for(d in D){
      if(nrow(df_temp[df_temp$Month==m & df_temp$District==d,])==0){
        add_data = c(d, m, 0)
        df_temp = rbind(df_temp, add_data)
      }
    }
  }
  df_temp$Count = as.integer(df_temp$Count)
  
  return(df_temp)
}
```


# Model
## Log-linear model 
I calculated $\lambda$ without considering the effects of "Month", "Weekday" and "District" in the midterm project. For final project, I will check these effects on the counts of each major crime  using a Log-linear model.

In a Log-linear model, response variable is a count of some occurrence that follows a Poisson distribution, and explanatory variables are categorical variables. The expected counts $\mu_{ij}$ is modeled as follows:
$$ \log(\mu_{ij})=\lambda + \lambda^A_i + \lambda^B_j + \lambda^{AB}_{ij}, $$
where $\lambda$ is a ground effect, $\lambda^A_i$ is the main effect of $i$ th level of A, and $\lambda^{AB}_{ij}$ is the interaction effect of $i$ th level of A and $j$ th level of B (if any).
  
# Method 
First, I divided the data into two prats: pre-COVID (2016-2019) and post-COVID (2020-2021). Then, each major crime case was classified by "District" and "Weekend". "District" has five levels (1D, 2D, 3D, 4D, 5D), and "Weekend" has two levels (0 (stands for weekday), 1 (stands for weekend)).
DC area are divided by seven police districts, but I excluded sixth and seventh districts because these districts have a very low crime rate, which makes the analysis difficult.  
  
I modeled the relationship between the counts of each major crime and categorical variables ("District" and "Weekend") using four independence models and the saturated model:
$${\rm{Model \ 1:}} \ \log(\mu_{ij})=\lambda.$$
$${\rm{Model \ 2:}} \ \log(\mu_{ij})=\lambda + \lambda^{District}_i.$$
$${\rm{Model \ 3:}} \ \log(\mu_{ij})=\lambda + \lambda^{Weekend}_j.$$
$${\rm{Model \ 4:}} \ \log(\mu_{ij})=\lambda + \lambda^{District}_i + \lambda^{Weekend}_j.$$
$${\rm{Model \ 5:}} \ \log(\mu_{ij})=\lambda + \lambda^{District}_i + \lambda^{Weekend}_j + \lambda^{District,Weekend}_{ij}.$$

```{r}
# create dataframe with "Category", "District", "Weekend"
DF_WM3 <- subset(DF_WM, Offense_Location_District %in% c('1D', '2D', '3D', '4D', '5D'))
DF_WM3$Offense_Location_District <- factor(DF_WM3$Offense_Location_District)
DF_WM3$Count <- c(rep(1,nrow(DF_WM3)))

DF_WM3$Weekend <- c(rep(0,nrow(DF_WM3)))
for(i in 1:nrow(DF_WM3)){
  if(DF_WM3$Weekday[i] %in% c('Saturday', 'Sunday')){
    DF_WM3$Weekend[i] = 1
  }
}
DF_WM3$Weekend <- as.factor(DF_WM3$Weekend)

# split the data into pre-COVID and post-COVID
DF_preCOVID = subset(DF_WM3, Arrest_Year %in% c(2016,2017,2018,2019))
DF_postCOVID = subset(DF_WM3, Arrest_Year %in% c(2020,2021))

# create dataframe with "Category", "District", "Weekend"
DF_preCOVID = aggregate(x=DF_preCOVID[c("Count")],
                           by=list(DF_preCOVID$Arrest_Category,
                                   DF_preCOVID$Offense_Location_District,
                                   DF_preCOVID$Weekend),
                           sum)
DF_postCOVID = aggregate(x=DF_postCOVID[c("Count")],
                            by=list(DF_postCOVID$Arrest_Category,
                                    DF_postCOVID$Offense_Location_District,
                                    DF_postCOVID$Weekend),
                            sum)
colnames(DF_preCOVID)[1:3] = c("Category", "District", "Weekend")
colnames(DF_postCOVID)[1:3] = c("Category", "District", "Weekend")

#DF_preCOVID %>% subset(., District != '#N/A') %>% subset(., District != 'Unk') %>% subset(., District != 'UNKNOWN') %>% subset(., District != '6D') %>%  subset(., District != '7D') -> DF_preCOVID

#DF_postCOVID %>% subset(., District != '#N/A') %>% subset(., District != 'Unk') %>% subset(., District != 'UNKNOWN') %>% subset(., District != '6D') %>%  subset(., District != '7D') -> DF_postCOVID

```

# Model Evaluation
## Simple Assault
```{r}
DF_preCOVID_SA = subset(DF_preCOVID, Category == 'Simple Assault')
DF_postCOVID_SA = subset(DF_postCOVID, Category == 'Simple Assault')
```
  
The two-way tables for "Simple Assault" are as follows.
  
```{r}
library("kableExtra")

d1 <- xtabs(Count ~ District + Weekend, data = DF_preCOVID_SA)
d2 <- xtabs(Count ~ District + Weekend, data = DF_postCOVID_SA)

kable(d1, format = "html", align = 'c', caption = 'Two-way table by "District" and "Weekend "(pre-COVID)') %>% 
  kable_styling(bootstrap_options = "hover", full_width = F, position = "float_left")
kable(d2, format = "html", align = 'c', caption = 'Two-way table by "District" and "Weekend" (post-COVID)') %>% 
  kable_styling(bootstrap_options = "hover", full_width = F, position = "center")
```


```{r, include=FALSE}
# pre-COVID

model1.pre.sa <- glm(Count ~ 1, data = DF_preCOVID_SA, family = poisson)
model2.pre.sa <- glm(Count ~ District, data = DF_preCOVID_SA, family = poisson)
model3.pre.sa <- glm(Count ~ Weekend, data = DF_preCOVID_SA, family = poisson)
model4.pre.sa <- glm(Count ~ District + Weekend, data = DF_preCOVID_SA, family = poisson)
model5.pre.sa <- glm(Count ~ District * Weekend, data = DF_preCOVID_SA, family = poisson)
summary(model1.pre.sa)
summary(model2.pre.sa)
summary(model3.pre.sa)
summary(model4.pre.sa)
summary(model5.pre.sa)
```

```{r, include=FALSE}
# post-COVID

model1.post.sa <- glm(Count ~ 1, data = DF_postCOVID_SA, family = poisson)
model2.post.sa <- glm(Count ~ District, data = DF_postCOVID_SA, family = poisson)
model3.post.sa <- glm(Count ~ Weekend, data = DF_postCOVID_SA, family = poisson)
model4.post.sa <- glm(Count ~ District + Weekend, data = DF_postCOVID_SA, family = poisson)
model5.post.sa <- glm(Count ~ District * Weekend, data = DF_postCOVID_SA, family = poisson)
summary(model1.post.sa)
summary(model2.post.sa)
summary(model3.post.sa)
summary(model4.post.sa)
summary(model5.post.sa)
```

### Deviance  

I used "residual deviance" to test the below hypothesis at a significance level $\alpha=0.05$:
$$H_0: \ \rm{Reduced \ model \ is \ true.}$$
$$H_1: \ \rm{Satureated \ model \ (Model \ 5) \ is \ true.}$$  
"residual deviance" is the difference between the deviance of the model and that of the saturated model. According to [The Pennsylvania State University website](https://online.stat.psu.edu/stat504/lesson/6/6.3/6.3.4), "residual deviance" follows a chi-square distribution with the model's degrees of freedom. Therefore, to test the hypothesis, I calculated p-values.  

**pre-COVID**  

| Model | Deviance | df | p-value |
|:-:|:-:|:-:|:-:|
| Model 1 | `r summary(model1.pre.sa)$deviance` | `r summary(model1.pre.sa)$df.residual` | `r pchisq(summary(model1.pre.sa)$deviance, summary(model1.pre.sa)$df.residual, lower.tail=FALSE)` | 
| Model 2 | `r summary(model2.pre.sa)$deviance` | `r summary(model2.pre.sa)$df.residual` | `r pchisq(summary(model2.pre.sa)$deviance, summary(model2.pre.sa)$df.residual, lower.tail=FALSE)` |
| Model 3 | `r summary(model3.pre.sa)$deviance` | `r summary(model3.pre.sa)$df.residual` | `r pchisq(summary(model3.pre.sa)$deviance, summary(model3.pre.sa)$df.residual, lower.tail=FALSE)` |
| Model 4 | `r summary(model4.pre.sa)$deviance` | `r summary(model4.pre.sa)$df.residual` | `r pchisq(summary(model4.pre.sa)$deviance, summary(model4.pre.sa)$df.residual, lower.tail=FALSE)` |
  
$H_0$ is rejected for all models.

  
**post-COVID**  

| Model | Deviance | df | p-value |
|:-:|:-:|:-:|:-:|
| Model 1 | `r summary(model1.post.sa)$deviance` | `r summary(model1.post.sa)$df.residual` | `r pchisq(summary(model1.post.sa)$deviance, summary(model1.post.sa)$df.residual, lower.tail=FALSE)` | 
| Model 2 | `r summary(model2.post.sa)$deviance` | `r summary(model2.post.sa)$df.residual` | `r pchisq(summary(model2.post.sa)$deviance, summary(model2.post.sa)$df.residual, lower.tail=FALSE)` |
| Model 3 | `r summary(model3.post.sa)$deviance` | `r summary(model3.post.sa)$df.residual` | `r pchisq(summary(model3.post.sa)$deviance, summary(model3.post.sa)$df.residual, lower.tail=FALSE)` |
| Model 4 | `r summary(model4.post.sa)$deviance` | `r summary(model4.post.sa)$df.residual` | `r pchisq(summary(model4.post.sa)$deviance, summary(model4.post.sa)$df.residual, lower.tail=FALSE)` |
  
For Model 4, $H_0$ is not rejected.  

### AIC and BIC
Each model's AIC and BIC was as follows.  

**pre-COVID**  
  
Model 5 is the best in terms of both AIC and BIC
  
| Model | AIC | BIC |
|:-:|:-:|:-:|
| Model 1 | `r AIC(model1.pre.sa)` |`r BIC(model1.pre.sa)` |
| Model 2 | `r AIC(model2.pre.sa)` |`r BIC(model2.pre.sa)` |
| Model 3 | `r AIC(model3.pre.sa)` |`r BIC(model3.pre.sa)` |
| Model 4 | `r AIC(model4.pre.sa)` |`r BIC(model4.pre.sa)` |
| Model 5 | `r AIC(model5.pre.sa)` |`r BIC(model5.pre.sa)` |

**post-COVID**  
  
Model 4 is the best in terms of both AIC and BIC.
  
| Model | AIC | BIC |
|:-:|:-:|:-:|
| Model 1 | `r AIC(model1.post.sa)` |`r BIC(model1.post.sa)` |
| Model 2 | `r AIC(model2.post.sa)` |`r BIC(model2.post.sa)` |
| Model 3 | `r AIC(model3.post.sa)` |`r BIC(model3.post.sa)` |
| Model 4 | `r AIC(model4.post.sa)` |`r BIC(model4.post.sa)` |
| Model 5 | `r AIC(model5.post.sa)` |`r BIC(model5.post.sa)` |

### Best Model  
Saturated model is the best for pre-COVID model. On the other hand, Independence model is the best for post-COVID model. 
  
#### Parameters  
**pre-COVID**  

Although the best model is the saturated model, almost all interaction terms are not significant. The interaction between "5D" and "weekend" is significant and has a negative value. This means the count of "Simple Assault" in 5D on weekend is fewer than the other districts.

```{r}
xkabledply(model5.pre.sa)
```


```{r}
createCIgraph <- function(model, cl, title_str){
  ci <- confint(model, level = cl)
  lb <- vector()
  ub <- vector()
  for(i in 1:(length(ci)/2)){
    lb = append(lb, ci[i,1])
    ub = append(ub, ci[i,2])
  }
  
  coef_label <- labels(coef(model))
  est <- data.frame(coeff_v = coef(model),
                    LB = lb,
                    UB = ub, 
                    var_name = coef_label)
  
  ggplot(est, aes(x = var_name, y = coeff_v)) +
    geom_point() +
    geom_errorbar(aes(ymin = lb, ymax = ub), width = 0.1) +
    geom_hline(yintercept = 0, lty = 1, color = "red") +
    theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
    scale_x_discrete(limits=coef_label) + 
    xlab("") +
    ylab("Estimated Parameter Value") + 
    ggtitle(title_str)
}
```

```{r}
createCIgraph(model5.pre.sa, 0.95, "95% Confidence Intervals of each parameter")
```

**post-COVID**  

```{r}
xkabledply(model4.post.sa)
```


```{r}
createCIgraph(model4.post.sa, 0.95, "95% Confidence Intervals of each parameter")
```


## Traffic Violations
```{r}
DF_preCOVID_TV = subset(DF_preCOVID, Category == 'Traffic Violations')
DF_postCOVID_TV = subset(DF_postCOVID, Category == 'Traffic Violations')
```

```{r}
d1 <- xtabs(Count ~ District + Weekend, data = DF_preCOVID_TV)
d2 <- xtabs(Count ~ District + Weekend, data = DF_postCOVID_TV)

kable(d1, format = "html", align = 'c', caption = 'Two-way table by "District" and "Weekend "(pre-COVID)') %>% 
  kable_styling(bootstrap_options = "hover", full_width = F, position = "float_left")
kable(d2, format = "html", align = 'c', caption = 'Two-way table by "District" and "Weekend" (post-COVID)') %>% 
  kable_styling(bootstrap_options = "hover", full_width = F, position = "center")
```

```{r, include=FALSE}
# pre-COVID

model1.pre.tv <- glm(Count ~ 1, data = DF_preCOVID_TV, family = poisson)
model2.pre.tv <- glm(Count ~ District, data = DF_preCOVID_TV, family = poisson)
model3.pre.tv <- glm(Count ~ Weekend, data = DF_preCOVID_TV, family = poisson)
model4.pre.tv <- glm(Count ~ District + Weekend, data = DF_preCOVID_TV, family = poisson)
model5.pre.tv <- glm(Count ~ District * Weekend, data = DF_preCOVID_TV, family = poisson)
summary(model1.pre.tv)
summary(model2.pre.tv)
summary(model3.pre.tv)
summary(model4.pre.tv)
summary(model5.pre.tv)
```

```{r, include=FALSE}
# post-COVID

model1.post.tv <- glm(Count ~ 1, data = DF_postCOVID_TV, family = poisson)
model2.post.tv <- glm(Count ~ District, data = DF_postCOVID_TV, family = poisson)
model3.post.tv <- glm(Count ~ Weekend, data = DF_postCOVID_TV, family = poisson)
model4.post.tv <- glm(Count ~ District + Weekend, data = DF_postCOVID_TV, family = poisson)
model5.post.tv <- glm(Count ~ District * Weekend, data = DF_postCOVID_TV, family = poisson)
summary(model1.post.tv)
summary(model2.post.tv)
summary(model3.post.tv)
summary(model4.post.tv)
summary(model5.post.tv)
```

### Deviance  

I tested the below hypothesis at a significance level $\alpha=0.05$:
$$H_0: \ \rm{Reduced \ model \ is \ true.}$$
$$H_1: \ \rm{Satureated \ model \ (Model \ 5) \ is \ true.}$$  


**pre-COVID**  

| Model | Deviance | df | p-value |
|:-:|:-:|:-:|:-:|
| Model 1 | `r summary(model1.pre.tv)$deviance` | `r summary(model1.pre.tv)$df.residual` | `r pchisq(summary(model1.pre.tv)$deviance, summary(model1.pre.tv)$df.residual, lower.tail=FALSE)` | 
| Model 2 | `r summary(model2.pre.tv)$deviance` | `r summary(model2.pre.tv)$df.residual` | `r pchisq(summary(model2.pre.tv)$deviance, summary(model2.pre.tv)$df.residual, lower.tail=FALSE)` |
| Model 3 | `r summary(model3.pre.tv)$deviance` | `r summary(model3.pre.tv)$df.residual` | `r pchisq(summary(model3.pre.tv)$deviance, summary(model3.pre.tv)$df.residual, lower.tail=FALSE)` |
| Model 4 | `r summary(model4.pre.tv)$deviance` | `r summary(model4.pre.tv)$df.residual` | `r pchisq(summary(model4.pre.tv)$deviance, summary(model4.pre.tv)$df.residual, lower.tail=FALSE)` |
  
$H_0$ is not rejected for Model 4.

  
**post-COVID**  

| Model | Deviance | df | p-value |
|:-:|:-:|:-:|:-:|
| Model 1 | `r summary(model1.post.tv)$deviance` | `r summary(model1.post.tv)$df.residual` | `r pchisq(summary(model1.post.tv)$deviance, summary(model1.post.tv)$df.residual, lower.tail=FALSE)` | 
| Model 2 | `r summary(model2.post.tv)$deviance` | `r summary(model2.post.tv)$df.residual` | `r pchisq(summary(model2.post.tv)$deviance, summary(model2.post.tv)$df.residual, lower.tail=FALSE)` |
| Model 3 | `r summary(model3.post.tv)$deviance` | `r summary(model3.post.tv)$df.residual` | `r pchisq(summary(model3.post.tv)$deviance, summary(model3.post.tv)$df.residual, lower.tail=FALSE)` |
| Model 4 | `r summary(model4.post.tv)$deviance` | `r summary(model4.post.tv)$df.residual` | `r pchisq(summary(model4.post.tv)$deviance, summary(model4.post.tv)$df.residual, lower.tail=FALSE)` |
  
$H_0$ is not rejected for Model 4.

### AIC  and BIC
Each model's AIC and BIC was as follows.  

**pre-COVID**  

Model 4 is the best in terms of AIC and BIC.
  
| Model | AIC | BIC |
|:-:|:-:|:-:|
| Model 1 | `r AIC(model1.pre.tv)` |`r BIC(model1.pre.tv)` |
| Model 2 | `r AIC(model2.pre.tv)` |`r BIC(model2.pre.tv)` |
| Model 3 | `r AIC(model3.pre.tv)` |`r BIC(model3.pre.tv)` |
| Model 4 | `r AIC(model4.pre.tv)` |`r BIC(model4.pre.tv)` |
| Model 5 | `r AIC(model5.pre.tv)` |`r BIC(model5.pre.tv)` |

**post-COVID**  

Model 5 is the best in terms of AIC, but Model 4 is the best from BIC. According to Chakrabarti & Ghosh (2011), "The Bayesian Information Criterion (BIC) is more useful in selecting a correct model while the AIC is more appropriate in finding the best model for predicting future observations." I want to select the correct model, not a model with high predictive power, so I will focus on the BIC results.
  
| Model | AIC | BIC |
|:-:|:-:|:-:|
| Model 1 | `r AIC(model1.post.tv)` |`r BIC(model1.post.tv)` |
| Model 2 | `r AIC(model2.post.tv)` |`r BIC(model2.post.tv)` |
| Model 3 | `r AIC(model3.post.tv)` |`r BIC(model3.post.tv)` |
| Model 4 | `r AIC(model4.post.tv)` |`r BIC(model4.post.tv)` |
| Model 5 | `r AIC(model5.post.tv)` |`r BIC(model5.post.tv)` |

### Best Model  
Independence model is the best for pre-COVID and post-COVID. 
  
#### Parameters  
**pre-COVID**  

```{r}
xkabledply(model4.pre.tv)
createCIgraph(model4.pre.tv, 0.95, "95% Confidence Intervals of each parameter")
```
  
  
**post-COVID**  

```{r}
xkabledply(model4.post.tv)
createCIgraph(model4.post.tv, 0.95, "95% Confidence Intervals of each parameter")
```


## Theft
```{r}
DF_preCOVID_Th = subset(DF_preCOVID, Category == 'Theft')
DF_postCOVID_Th = subset(DF_postCOVID, Category == 'Theft')
```

```{r}
d1 <- xtabs(Count ~ District + Weekend, data = DF_preCOVID_Th)
d2 <- xtabs(Count ~ District + Weekend, data = DF_postCOVID_Th)

kable(d1, format = "html", align = 'c', caption = 'Two-way table by "District" and "Weekend "(pre-COVID)') %>% 
  kable_styling(bootstrap_options = "hover", full_width = F, position = "float_left")
kable(d2, format = "html", align = 'c', caption = 'Two-way table by "District" and "Weekend" (post-COVID)') %>% 
  kable_styling(bootstrap_options = "hover", full_width = F, position = "center")
```


```{r, include=FALSE}
# pre-COVID

model1.pre.th <- glm(Count ~ 1, data = DF_preCOVID_Th, family = poisson)
model2.pre.th <- glm(Count ~ District, data = DF_preCOVID_Th, family = poisson)
model3.pre.th <- glm(Count ~ Weekend, data = DF_preCOVID_Th, family = poisson)
model4.pre.th <- glm(Count ~ District + Weekend, data = DF_preCOVID_Th, family = poisson)
model5.pre.th <- glm(Count ~ District * Weekend, data = DF_preCOVID_Th, family = poisson)
summary(model1.pre.th)
summary(model2.pre.th)
summary(model3.pre.th)
summary(model4.pre.th)
summary(model5.pre.th)
```

```{r, include=FALSE}
# post-COVID

model1.post.th <- glm(Count ~ 1, data = DF_postCOVID_Th, family = poisson)
model2.post.th <- glm(Count ~ District, data = DF_postCOVID_Th, family = poisson)
model3.post.th <- glm(Count ~ Weekend, data = DF_postCOVID_Th, family = poisson)
model4.post.th <- glm(Count ~ District + Weekend, data = DF_postCOVID_Th, family = poisson)
model5.post.th <- glm(Count ~ District * Weekend, data = DF_postCOVID_Th, family = poisson)
summary(model1.post.th)
summary(model2.post.th)
summary(model3.post.th)
summary(model4.post.th)
summary(model5.post.th)
```

### Deviance  

I tested the below hypothesis at a significance level $\alpha=0.05$:
$$H_0: \ \rm{Reduced \ model \ is \ true.}$$
$$H_1: \ \rm{Satureated \ model \ (Model \ 5) \ is \ true.}$$  

**pre-COVID**  

| Model | Deviance | df | p-value |
|:-:|:-:|:-:|:-:|
| Model 1 | `r summary(model1.pre.th)$deviance` | `r summary(model1.pre.th)$df.residual` | `r pchisq(summary(model1.pre.th)$deviance, summary(model1.pre.th)$df.residual, lower.tail=FALSE)` | 
| Model 2 | `r summary(model2.pre.th)$deviance` | `r summary(model2.pre.th)$df.residual` | `r pchisq(summary(model2.pre.th)$deviance, summary(model2.pre.th)$df.residual, lower.tail=FALSE)` |
| Model 3 | `r summary(model3.pre.th)$deviance` | `r summary(model3.pre.th)$df.residual` | `r pchisq(summary(model3.pre.th)$deviance, summary(model3.pre.th)$df.residual, lower.tail=FALSE)` |
| Model 4 | `r summary(model4.pre.th)$deviance` | `r summary(model4.pre.th)$df.residual` | `r pchisq(summary(model4.pre.th)$deviance, summary(model4.pre.th)$df.residual, lower.tail=FALSE)` |
  
$H_0$ is not rejected for Model 4.

  
**post-COVID**  

| Model | Deviance | df | p-value |
|:-:|:-:|:-:|:-:|
| Model 1 | `r summary(model1.post.th)$deviance` | `r summary(model1.post.th)$df.residual` | `r pchisq(summary(model1.post.th)$deviance, summary(model1.post.th)$df.residual, lower.tail=FALSE)` | 
| Model 2 | `r summary(model2.post.th)$deviance` | `r summary(model2.post.th)$df.residual` | `r pchisq(summary(model2.post.th)$deviance, summary(model2.post.th)$df.residual, lower.tail=FALSE)` |
| Model 3 | `r summary(model3.post.th)$deviance` | `r summary(model3.post.th)$df.residual` | `r pchisq(summary(model3.post.th)$deviance, summary(model3.post.th)$df.residual, lower.tail=FALSE)` |
| Model 4 | `r summary(model4.post.th)$deviance` | `r summary(model4.post.th)$df.residual` | `r pchisq(summary(model4.post.th)$deviance, summary(model4.post.th)$df.residual, lower.tail=FALSE)` |
  
$H_0$ is not rejected for Model 4.

### AIC and BIC   
Each model's AIC and BIC was as follows.  

**pre-COVID**  
  
Model 4 is the best in terms of AIC and BIC.
  
| Model | AIC | BIC |
|:-:|:-:|:-:|
| Model 1 | `r AIC(model1.pre.th)` |`r BIC(model1.pre.th)` |
| Model 2 | `r AIC(model2.pre.th)` |`r BIC(model2.pre.th)` |
| Model 3 | `r AIC(model3.pre.th)` |`r BIC(model3.pre.th)` |
| Model 4 | `r AIC(model4.pre.th)` |`r BIC(model4.pre.th)` |
| Model 5 | `r AIC(model5.pre.th)` |`r BIC(model5.pre.th)` |

**post-COVID**  

Model 4 is the best in terms of AIC and BIC.
  
| Model | AIC | BIC |
|:-:|:-:|:-:|
| Model 1 | `r AIC(model1.post.th)` |`r BIC(model1.post.th)` |
| Model 2 | `r AIC(model2.post.th)` |`r BIC(model2.post.th)` |
| Model 3 | `r AIC(model3.post.th)` |`r BIC(model3.post.th)` |
| Model 4 | `r AIC(model4.post.th)` |`r BIC(model4.post.th)` |
| Model 5 | `r AIC(model5.post.th)` |`r BIC(model5.post.th)` |  

### Best Model  

**pre-COVID**  

```{r}
xkabledply(model4.pre.th)
createCIgraph(model4.pre.th, 0.95, "95% Confidence Intervals of each parameter")
```
  
**post-COVID**
  
```{r}
xkabledply(model4.post.th)
createCIgraph(model4.post.th, 0.95, "95% Confidence Intervals of each parameter")
```

# Interpretation  
  
* "Weekend = 1" has a negative parameter in all models. However, this does not mean that there are fewer crimes on weekends than on other weekdays. This is because only Saturdays and Sundays are classified as "Weekend = 1", and the number of days classified as "Weekend = 0" is 2.5 times greater.
* Through pre-COVID and post-COVID, the fact that a district is 2D, 3D, or 4D tends to drive up the number of crimes. This is not surprising since these districts are in the Northwest area, which has a large population.  
* The combination of 5D and "Weekend = 1" has the effect of pushing down the number of "Simple Assault" during post-COVID period. This may be due to the fact that the main tourist areas are in the Northwest District, which attracts more people to this area on weekends than to 5D. The interaction between 5D and "Weekend" may have disappeared because outings were suppressed in all districts after COVID-19 outbreak.  
* Prior to 2019, 5D had the effect of pushing down the number of thefts relative to other districts, but after 2020, 5D has the effect of pushing up the number of thefts relative to other districts.  
  
# Conclusion  

COVID-19 appears to not only reduce the number of crimes, but also change crime trends. In particular, 5D seems to have changed crime trends compared to other districts.

# Refereance  
Chakrabarti, A., & Ghosh, J. K. (2011). AIC, BIC and recent advances in model selection. Philosophy of statistics, 583-605.
