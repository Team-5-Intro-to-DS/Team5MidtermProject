---
title: "final project team 5"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
date: "`r Sys.Date()`"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(ggplot2)
library(ezids)
library(dplyr)
library(readr)
library(tidyr)
library(knitr)
library(magrittr)

df_2016<-data.frame(read.csv("Arrests 2016 Public.csv"))
df_2017<-data.frame(read.csv("Arrests 2017 Public.csv"))
df_2018<-data.frame(read.csv("Arrests by Year, 2018.csv"))
df_2019<-data.frame(read.csv("Arrests by Year, 2019.csv"))
df_2020<-data.frame(read.csv("Arrests by Year 2020.csv"))
df_2021<-data.frame(read.csv("2021 Adult Arrests.csv"))

# convert format
df_2018$Arrest.Date <- as.Date(df_2018$Arrest.Date, format = "%m/%d/%Y") %>% format()
df_2019$Arrest.Date <- as.Date(df_2019$Arrest.Date, format = "%m/%d/%Y") %>% format()
df_2020$Arrest.Date <- as.Date(df_2020$Arrest.Date, format = "%m/%d/%Y") %>% format()
df_2021$Arrest.Date <- as.Date(df_2021$Arrest.Date, format = "%Y/%m/%d") %>% format()

#bind df_2016 and df_2017, and delete some columns
df_16_17 <- rbind(df_2016, df_2017)[,-c(5,6,15,17:21,23:26)]
names(df_16_17)[c(13,14)] <- c('Arrest.Location.District','Offense.Location.District')   #rename columns

#bind df_2018 - df_2021, and delete some columns
df_18_21 <- rbind(df_2018, df_2019, df_2020, df_2021)[,-c(5,6,15,17:21,23:26)] 

DF<-rbind(df_16_17,df_18_21)

# remove abnormalities
DF <- DF[!DF$Age>=100,]

# replace dots with underscore for clarity sake, i think..
names(DF) = gsub("[.]", "_", names(DF))

# most likely "UNK" is the same as "Unknown", so we can change this
DF$Defendant_Race[DF$Defendant_Race == 'UNK'] <- 'UNKNOWN'
#unique(DF$Defendant_Race) - check that it changed

#same issue, "unk" is very likely "unknown", so change it.
DF$Defendant_Sex[DF$Defendant_Sex == 'UNK'] <- 'UNKNOWN'
#unique(DF$Defendant_Sex) - check that it changed

# Arrest category -  4 different types of Fraud & Financial crimes , 3 types of Release Violations/Fugitive -- group them into one.

DF$Arrest_Category = gsub("Fraud and Financial Crimes.*","Fraud and Financial Crimes", DF$Arrest_Category)

DF$Arrest_Category = gsub("Release Violations/Fugitive.*","Release Violations/Fugitive",DF$Arrest_Category)

#get month and day variables.. might be interesting, who knows?
DF <- separate(DF, col = Arrest_Date, into = c("Year","Month","Day"), sep = "-", remove = FALSE, fill="left")
#remove the new year column formed, it is redundant.. we already have Year column
DF = DF[,-4]

library(lubridate)
# Factorize some variables
DF$Arrest_Year = as.factor(DF$Arrest_Year)
DF$Month = as.factor(DF$Month)
DF$Day = as.factor(DF$Day)
DF$Defendant_Race = as.factor(DF$Defendant_Race)
DF$Defendant_Sex = as.factor(DF$Defendant_Sex)
DF$Arrest_Location_District = as.factor(DF$Arrest_Location_District)
DF$Offense_Location_District = as.factor(DF$Offense_Location_District)
# convert to date format
DF$Arrest_Date = as.Date(DF$Arrest_Date)
# Day format
DF$Day = day(DF$Arrest_Date)
# i want to create a week-day variable
DF$Weekday = weekdays(DF$Arrest_Date)
DF$Weekday = factor(DF$Weekday, levels = as.character(wday(c(2:7,1), label=TRUE, abbr=FALSE)))

# convert crime types to factors
DF$Arrest_Category = as.factor(DF$Arrest_Category)

DF_WM <- subset(DF, subset = Defendant_Race=='WHITE' & Defendant_Sex=='MALE')

```


```{r}
# create dataframe having "Category", "Month", "District", "Year", and "Count" as its column
DF_WM2 <- DF_WM
DF_WM2$Count <- c(rep(1,nrow(DF_WM2)))

DF_WM2 = aggregate(x=DF_WM2[c("Count")], 
                   by=list(DF_WM2$Arrest_Category, DF_WM2$Month, DF_WM2$Weekday,
                           DF_WM2$Offense_Location_District, DF_WM2$Arrest_Year),
                   sum)

colnames(DF_WM2)[1:5] = c("Category", "Month", "Weekday", "District", "Year")
DF_WM2 = subset(DF_WM2, DF_WM2$District != '#N/A')
```



```{r}
# create a function (createDF) adding "Count" = 0 rows and "Weekend" column (0 for weekday, 1 for weekend)
# createDF takes dataframe and crime category as its arguments, and returns a dataframe having "Category", "Month", "Weekday", "District", "Year", "Count", "Weekend"

createDF <- function(df, CrimeCategory){
  M <- c('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12')
  W <- c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday')
  D <- c('1D','2D','3D','4D','5D','6D','7D' )
  Y <- c('2016', '2017', '2018', '2019', '2020', '2021')
  
  df_temp = subset(df, df$Category==CrimeCategory)
  
  # add "Count" = 0 rows
  for(m in M){
    for(w in W){
      for(d in D){
        for(y in Y){
          if(nrow(df_temp[df_temp$Month==m & df_temp$Weekday==w & df_temp$District==d & df_temp$Year==y,])==0){
            add_data = c(CrimeCategory, m, w, d, y, 0)
            df_temp = rbind(df_temp, add_data)
          }
        }
      }
    }
  }
  df_temp$Count = as.integer(df_temp$Count)
  
  # add "Weekend" column
  df_temp$Weekend <- c(rep(0,nrow(df_temp)))
  for(i in 1:nrow(df_temp)){
    if(df_temp[i,'Weekday'] %in% c('Saturday', 'Sunday')){
      df_temp[i,'Weekend'] = 1
    }
  }
  df_temp$Weekend <- as.factor(df_temp$Weekend)
  
  return(df_temp)
}
```


```{r}
createHist <- function(df){
  M <- c('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12')
  W <- c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday')
  D <- c('1D','2D','3D','4D','5D','6D','7D' )
  for(w in W){
    df_temp <- subset(df, df$Weekday==w)
    hist(df_temp$Count, breaks=max(df_temp$Count))
  }
}
```

# Poisson Regression (Log-linear) 
I calculated $\lambda$ without considering the effects of "Month", "Weekday" and "District" in the midterm project. For final project, I will check these effects on $\lambda$ using Poisson regression.
  
According to [The Pennsylvania State University website](https://online.stat.psu.edu/stat504/lesson/9),  

> Poisson regression is also a special case of the generalized linear model, where the random component is specified by the Poisson distribution. This usually works well when the response variable is a count of some occurrence.

I can get a count of each crime from our dataset, so I will try Poisson regression.  

In Poisson regression, response are assumed to be follow a Poisson distribution, and the link function is log. Therefore, the model will be as follows:  
$$\log(\mu=\lambda) = b_0 + b_1x_1 + b_2x_2 + \cdot\cdot\cdot + b_nx_n,$$
where $x_i$ is explanatory variables. "Month", "Weekday" and "District" are categorical, so $x_i$ are dummy variables in our model.

According to [The Pennsylvania State University website](https://online.stat.psu.edu/stat504/lesson/9),  

> When all explanatory variables are discrete, the Poisson regression model is equivalent to the log-linear model  

Therefore, to be precise, our model would be a log-linear model.

## Simple Assault

```{r}
DF_WM2_SA <- createDF(DF_WM2, 'Simple Assault')

DF_WM2_SA_preCOVID <- subset(DF_WM2_SA, DF_WM2_SA$Year %in% c('2016', '2017', '2018', '2019'))
DF_WM2_SA_postCOVID <- subset(DF_WM2_SA, DF_WM2_SA$Year %in% c('2020', '2021'))
```

Our data is as follows:  
```{r}
xkabledplyhead(DF_WM2_SA, title = "First five rows")
```
I will divide this data into pre-COVID (2016-2019) and post-COVID (2020-2021), and create models for each data.

### Models for pre-COVID
##### Model1: Count ~ Month + Weekday + District  

```{r}
preModel1 <- glm(Count ~ Month + Weekday + District, data = DF_WM2_SA_preCOVID, family = poisson)
xkabledply(preModel1)
```

The coefficients of Tuesday to Friday are not significant, so I will try "Weekend" instead of "Weekday".

##### Model2: Count ~ Month + Weekend + District  

```{r}
preModel2 <- glm(Count ~ Month + Weekend + District, data = DF_WM2_SA_preCOVID, family = poisson)
xkabledply(preModel2)
```

Most of months do not have a significant coefficient, so I will drop "Month" from variables.

##### Model3: Count ~ Weekday + District  
```{r}
preModel3 <- glm(Count ~ Weekday + District, data = DF_WM2_SA_preCOVID, family = poisson)
xkabledply(preModel3)
```

##### Model4: Count ~ Weekend + District  
```{r}
preModel4 <- glm(Count ~ Weekend + District, data = DF_WM2_SA_preCOVID, family = poisson)
xkabledply(preModel4)
```

##### Model5: Count ~ District  
```{r}
preModel5 <- glm(Count ~ District, data = DF_WM2_SA_preCOVID, family = poisson)
xkabledply(preModel5)
```

#### Model Evaluation  
##### Deviance  
I will use "residual deviance" to test whether the null hypothesis (Poisson regression model provides an adequate fit for the data) is true. To test the null hypothesis, I will calculate p-value:  

| Model | Model1 | Model2 | Model3 | Model4 | Model5 |
|:-:|:-:|:-:|:-:|:-:|:-:|
| **p-value** | `r pchisq(summary(preModel1)$deviance, summary(preModel1)$df.residual, lower.tail=FALSE)` | `r pchisq(summary(preModel2)$deviance, summary(preModel2)$df.residual, lower.tail=FALSE)` | `r pchisq(summary(preModel3)$deviance, summary(preModel3)$df.residual, lower.tail=FALSE)` | `r pchisq(summary(preModel4)$deviance, summary(preModel4)$df.residual, lower.tail=FALSE)` | `r pchisq(summary(preModel5)$deviance, summary(preModel5)$df.residual, lower.tail=FALSE)` |

Null hypothesis is not rejected except for Model 5.

##### pseudo-R2  
Check MacFadden's pseudo r-squared for each model.  

```{r, include=FALSE}
loadPkg("pscl")
```

| Model | Model1 | Model2 | Model3 | Model4 | Model5 |
|:-:|:-:|:-:|:-:|:-:|:-:|
| **pseudo R2** | `r pR2(preModel1)["McFadden"]` | `r pR2(preModel2)["McFadden"]` | `r pR2(preModel3)["McFadden"]` | `r pR2(preModel4)["McFadden"]` | `r pR2(preModel5)["McFadden"]` |

About 23% of variance in the response can be explained in Model1 to Model4.

##### AIC
Check AIC for each model.

| Model | Model1 | Model2 | Model3 | Model4 | Model5 |
|:-:|:-:|:-:|:-:|:-:|:-:|
| **AIC** | `r AIC(preModel1)` | `r AIC(preModel2)` | `r AIC(preModel3)` | `r AIC(preModel4)` | `r AIC(preModel5)` |

Model 3 is the best in terms of AIC.

##### BIC
Check BIC for each model.

| Model | Model1 | Model2 | Model3 | Model4 | Model5 |
|:-:|:-:|:-:|:-:|:-:|:-:|
| **BIC** | `r BIC(preModel1)` | `r BIC(preModel2)` | `r BIC(preModel3)` | `r BIC(preModel4)` | `r AIC(preModel5)` |

Model 4 is the best in terms of BIC.



### Models for post-COVID
#### Model1: Count ~ Month + Weekday + District  
```{r}
postModel1 <- glm(Count ~ Month + Weekday + District, data = DF_WM2_SA_postCOVID, family = poisson)
xkabledply(summary(postModel1))
```
The coefficients of Tuesday to Friday are not significant, so I will try "Weekend" instead of "Weekday".

#### Model2: Count ~ Month + Weekend + District  
```{r}
postModel2 <- glm(Count ~ Month + Weekend + District, data = DF_WM2_SA_postCOVID, family = poisson)
xkabledply(summary(postModel2))
```

#### Model3: Count ~ Month + District  
```{r}
postModel3 <- glm(Count ~ Month + District, data = DF_WM2_SA_postCOVID, family = poisson)
xkabledply(summary(postModel3))
```

#### Model4: Count ~ Weekday + District  
```{r}
postModel4 <- glm(Count ~ Weekday + District, data = DF_WM2_SA_postCOVID, family = poisson)
xkabledply(summary(postModel4))
```

#### Model5: Count ~ Weekend + District  
```{r}
postModel5 <- glm(Count ~ Weekend + District, data = DF_WM2_SA_postCOVID, family = poisson)
xkabledply(summary(postModel5))
```

#### Model6: Count ~ District  
```{r}
postModel6 <- glm(Count ~ District, data = DF_WM2_SA_postCOVID, family = poisson)
xkabledply(summary(postModel6))
```


#### Model Evaluation  
##### Deviance  
I will use "residual deviance" to test whether the null hypothesis (Poisson regression model provides an adequate fit for the data) is true. To test the null hypothesis, I will calculate p-value:  

| Model | Model1 | Model2 | Model3 | Model4 | Model5 | Model6 |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
| **p-value** | `r pchisq(summary(postModel1)$deviance, summary(postModel1)$df.residual, lower.tail=FALSE)` | `r pchisq(summary(postModel2)$deviance, summary(postModel2)$df.residual, lower.tail=FALSE)` | `r pchisq(summary(postModel3)$deviance, summary(postModel3)$df.residual, lower.tail=FALSE)` | `r pchisq(summary(postModel4)$deviance, summary(postModel4)$df.residual, lower.tail=FALSE)` | `r pchisq(summary(postModel5)$deviance, summary(postModel5)$df.residual, lower.tail=FALSE)` | `r pchisq(summary(postModel6)$deviance, summary(postModel6)$df.residual, lower.tail=FALSE)` |

Null hypothesis is not rejected except.

##### pseudo-R2  
Check MacFadden's pseudo r-squared for each model.  

| Model | Model1 | Model2 | Model3 | Model4 | Model5 | Model6 |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
| **pseudo R2** | `r pR2(postModel1)["McFadden"]` | `r pR2(postModel2)["McFadden"]` | `r pR2(postModel3)["McFadden"]` | `r pR2(postModel4)["McFadden"]` | `r pR2(postModel5)["McFadden"]` | `r pR2(postModel6)["McFadden"]` |

About 15 ~ 17% of variance in the response can be explained in Model1 to Model5.

##### AIC
Check AIC for each model.

| Model | Model1 | Model2 | Model3 | Model4 | Model5 | Model |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
| **AIC** | `r AIC(postModel1)` | `r AIC(postModel2)` | `r AIC(postModel3)` | `r AIC(postModel4)` | `r AIC(postModel5)` | `r AIC(postModel6)` |

Model 2 is the best in terms of AIC.

##### BIC
Check BIC for each model.

| Model | Model1 | Model2 | Model3 | Model4 | Model5 | Model6 |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
| **BIC** | `r BIC(postModel1)` | `r BIC(postModel2)` | `r BIC(postModel3)` | `r BIC(postModel4)` | `r BIC(postModel5)` | `r BIC(postModel6)` |

Model 5 is the best in terms of BIC.
