---
title: "final project team 5"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
date: "`r Sys.Date()`"
editor_options: 
  markdown: 
    wrap: 72
---

# Investigation in DC crime trend 2016-2021

Professor: Dr. Farhana Faruqe

DATS-6101: Introduction to Data Science

Member: Xuanyu Chen, Yuchuan Feng, Ore Asaba, Kentaro Osawa, Adewale Maye  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(ggplot2)
library(ezids)
library(dplyr)
library(readr)
library(tidyr)
library(knitr)
library(magrittr)

# This chunk is for data cleaning, the same as was done in the midterm project.

df_2016<-data.frame(read.csv("Arrests 2016 Public.csv"))
df_2017<-data.frame(read.csv("Arrests 2017 Public.csv"))
df_2018<-data.frame(read.csv("Arrests by Year, 2018.csv"))
df_2019<-data.frame(read.csv("Arrests by Year, 2019.csv"))
df_2020<-data.frame(read.csv("Arrests by Year 2020.csv"))
df_2021<-data.frame(read.csv("2021 Adult Arrests.csv"))

# convert format
df_2018$Arrest.Date <- as.Date(df_2018$Arrest.Date, format = "%m/%d/%Y") %>% format()
df_2019$Arrest.Date <- as.Date(df_2019$Arrest.Date, format = "%m/%d/%Y") %>% format()
df_2020$Arrest.Date <- as.Date(df_2020$Arrest.Date, format = "%m/%d/%Y") %>% format()
df_2021$Arrest.Date <- as.Date(df_2021$Arrest.Date, format = "%Y/%m/%d") %>% format()

#bind df_2016 and df_2017, and delete some columns
df_16_17 <- rbind(df_2016, df_2017)[,-c(5,6,15,17:21,23:26)]
names(df_16_17)[c(13,14)] <- c('Arrest.Location.District','Offense.Location.District')   #rename columns

#bind df_2018 - df_2021, and delete some columns
df_18_21 <- rbind(df_2018, df_2019, df_2020, df_2021)[,-c(5,6,15,17:21,23:26)] 

DF<-rbind(df_16_17,df_18_21)

# remove abnormalities
DF <- DF[!DF$Age>=100,]

# replace dots with underscore for clarity sake, i think..
names(DF) = gsub("[.]", "_", names(DF))

# most likely "UNK" is the same as "Unknown", so we can change this
DF$Defendant_Race[DF$Defendant_Race == 'UNK'] <- 'UNKNOWN'
#unique(DF$Defendant_Race) - check that it changed

#same issue, "unk" is very likely "unknown", so change it.
DF$Defendant_Sex[DF$Defendant_Sex == 'UNK'] <- 'UNKNOWN'
#unique(DF$Defendant_Sex) - check that it changed

# Arrest category -  4 different types of Fraud & Financial crimes , 3 types of Release Violations/Fugitive -- group them into one.

DF$Arrest_Category = gsub("Fraud and Financial Crimes.*","Fraud and Financial Crimes", DF$Arrest_Category)

DF$Arrest_Category = gsub("Release Violations/Fugitive.*","Release Violations/Fugitive",DF$Arrest_Category)

#get month and day variables.. might be interesting, who knows?
DF <- separate(DF, col = Arrest_Date, into = c("Year","Month","Day"), sep = "-", remove = FALSE, fill="left")
#remove the new year column formed, it is redundant.. we already have Year column
DF = DF[,-4]

library(lubridate)
# Factorize some variables
DF$Arrest_Year = as.factor(DF$Arrest_Year)
DF$Month = as.factor(DF$Month)
DF$Day = as.factor(DF$Day)
DF$Defendant_Race = as.factor(DF$Defendant_Race)
DF$Defendant_Sex = as.factor(DF$Defendant_Sex)
DF$Arrest_Location_District = as.factor(DF$Arrest_Location_District)
DF$Offense_Location_District = as.factor(DF$Offense_Location_District)
# convert to date format
DF$Arrest_Date = as.Date(DF$Arrest_Date)
# Day format
DF$Day = day(DF$Arrest_Date)
# i want to create a week-day variable
DF$Weekday = weekdays(DF$Arrest_Date)
DF$Weekday = factor(DF$Weekday, levels = as.character(wday(c(2:7,1), label=TRUE, abbr=FALSE)))

# convert crime types to factors
DF$Arrest_Category = as.factor(DF$Arrest_Category)

DF_WM <- subset(DF, subset = Defendant_Race=='WHITE' & Defendant_Sex=='MALE')

```


# Model
## Log-linear model 
We calculated $\lambda$ without considering the effects of "Month", "Weekday" and "District" in the midterm project. For final project, We will check these effects on the counts of each major crime  using a Log-linear model.

In a Log-linear model, response variable is a count of some occurrence that follows a Poisson distribution, and explanatory variables are categorical variables. The expected counts $\mu_{ij}$ is modeled as follows:
$$ \log(\mu_{ij})=\lambda + \lambda^A_i + \lambda^B_j + \lambda^{AB}_{ij}, $$
where $\lambda$ is a ground effect, $\lambda^A_i$ is the main effect of $i$ th level of A, and $\lambda^{AB}_{ij}$ is the interaction effect of $i$ th level of A and $j$ th level of B (if any) ([https://online.stat.psu.edu/stat504/lesson/10](https://online.stat.psu.edu/stat504/lesson/10)).
  
# Method 
First, We divided the data into two prats: pre-COVID (2016-2019) and post-COVID (2020-2021). Then, each major crime case was classified by "District" and "Weekend". "District" has five levels (1D, 2D, 3D, 4D, 5D), and "Weekend" has two levels (0 (stands for weekday), 1 (stands for weekend)).
DC area are divided by seven police districts, but We excluded sixth and seventh districts because these districts have a very low crime rate, which makes the analysis difficult.  
  
We modeled the relationship between the counts of each major crime and categorical variables ("District" and "Weekend") using four independence models and the saturated model:  
$${\rm{Model \ 1:}} \ \log(\mu_{ij})=\lambda.$$
$${\rm{Model \ 2:}} \ \log(\mu_{ij})=\lambda + \lambda^{District}_i.$$
$${\rm{Model \ 3:}} \ \log(\mu_{ij})=\lambda + \lambda^{Weekend}_j.$$
$${\rm{Model \ 4:}} \ \log(\mu_{ij})=\lambda + \lambda^{District}_i + \lambda^{Weekend}_j.$$
$${\rm{Model \ 5:}} \ \log(\mu_{ij})=\lambda + \lambda^{District}_i + \lambda^{Weekend}_j + \lambda^{District,Weekend}_{ij}.$$


```{r}
# This chunk is for creating new dataframe used to conduct log-linear analysis

# drop the rows in which "Offense_Location_District" is '6D' or '7D'
DF_WM2 <- subset(DF_WM, Offense_Location_District %in% c('1D', '2D', '3D', '4D', '5D'))
DF_WM2$Offense_Location_District <- factor(DF_WM2$Offense_Location_District)

# create a new row named "Count"
DF_WM2$Count <- c(rep(1,nrow(DF_WM2)))

# create a new row named "Weekend" that takes 0 for Mon - Fri and 1 for Sat and Sun
DF_WM2$Weekend <- c(rep(0,nrow(DF_WM2)))
for(i in 1:nrow(DF_WM2)){
  if(DF_WM2$Weekday[i] %in% c('Saturday', 'Sunday')){
    DF_WM2$Weekend[i] = 1
  }
}
DF_WM2$Weekend <- as.factor(DF_WM2$Weekend)

# split the data into pre-COVID and post-COVID
DF_preCOVID = subset(DF_WM2, Arrest_Year %in% c(2016,2017,2018,2019))
DF_postCOVID = subset(DF_WM2, Arrest_Year %in% c(2020,2021))

# create dataframe with "Category", "District", "Weekend", and "Count"
DF_preCOVID = aggregate(x=DF_preCOVID[c("Count")],
                           by=list(DF_preCOVID$Arrest_Category,
                                   DF_preCOVID$Offense_Location_District,
                                   DF_preCOVID$Weekend),
                           sum)
DF_postCOVID = aggregate(x=DF_postCOVID[c("Count")],
                            by=list(DF_postCOVID$Arrest_Category,
                                    DF_postCOVID$Offense_Location_District,
                                    DF_postCOVID$Weekend),
                            sum)

# rename some columns
colnames(DF_preCOVID)[1:3] = c("Category", "District", "Weekend")
colnames(DF_postCOVID)[1:3] = c("Category", "District", "Weekend")
```

# Model Evaluation
## Simple Assault
```{r}
DF_preCOVID_SA = subset(DF_preCOVID, Category == 'Simple Assault')
DF_postCOVID_SA = subset(DF_postCOVID, Category == 'Simple Assault')
```
  
The two-way tables for "Simple Assault" are as follows.
  
```{r}
#This chunk is for creating two-way tables

library("kableExtra")

d1 <- xtabs(Count ~ District + Weekend, data = DF_preCOVID_SA)
d2 <- xtabs(Count ~ District + Weekend, data = DF_postCOVID_SA)

kable(d1, format = "html", align = 'c', caption = 'Two-way table by "District" and "Weekend "(pre-COVID)') %>% 
  kable_styling(bootstrap_options = "hover", full_width = F, position = "float_left")
kable(d2, format = "html", align = 'c', caption = 'Two-way table by "District" and "Weekend" (post-COVID)') %>% 
  kable_styling(bootstrap_options = "hover", full_width = F, position = "center")
```


```{r, include=FALSE}
# models for pre-COVID

model1.pre.sa <- glm(Count ~ 1, data = DF_preCOVID_SA, family = poisson)
model2.pre.sa <- glm(Count ~ District, data = DF_preCOVID_SA, family = poisson)
model3.pre.sa <- glm(Count ~ Weekend, data = DF_preCOVID_SA, family = poisson)
model4.pre.sa <- glm(Count ~ District + Weekend, data = DF_preCOVID_SA, family = poisson)
model5.pre.sa <- glm(Count ~ District * Weekend, data = DF_preCOVID_SA, family = poisson)
```

```{r, include=FALSE}
# models for post-COVID

model1.post.sa <- glm(Count ~ 1, data = DF_postCOVID_SA, family = poisson)
model2.post.sa <- glm(Count ~ District, data = DF_postCOVID_SA, family = poisson)
model3.post.sa <- glm(Count ~ Weekend, data = DF_postCOVID_SA, family = poisson)
model4.post.sa <- glm(Count ~ District + Weekend, data = DF_postCOVID_SA, family = poisson)
model5.post.sa <- glm(Count ~ District * Weekend, data = DF_postCOVID_SA, family = poisson)
```

### Deviance  

We used "residual deviance" to test the below hypothesis at a significance level $\alpha=0.05$:
$$H_0: \ \rm{Reduced \ model \ is \ true.}$$
$$H_1: \ \rm{Satureated \ model \ (Model \ 5) \ is \ true.}$$  
"residual deviance" is the difference between the deviance of the model and that of the saturated model. According to The Pennsylvania State University website ([https://online.stat.psu.edu/stat504/lesson/6/6.3/6.3.4](https://online.stat.psu.edu/stat504/lesson/6/6.3/6.3.4 )), "residual deviance" follows a chi-square distribution with the model's degrees of freedom. Therefore, to test the hypothesis, I calculated p-values.  

**pre-COVID**  

| Model | Deviance | df | p-value |
|:-:|:-:|:-:|:-:|
| Model 1 | `r summary(model1.pre.sa)$deviance` | `r summary(model1.pre.sa)$df.residual` | `r pchisq(summary(model1.pre.sa)$deviance, summary(model1.pre.sa)$df.residual, lower.tail=FALSE)` | 
| Model 2 | `r summary(model2.pre.sa)$deviance` | `r summary(model2.pre.sa)$df.residual` | `r pchisq(summary(model2.pre.sa)$deviance, summary(model2.pre.sa)$df.residual, lower.tail=FALSE)` |
| Model 3 | `r summary(model3.pre.sa)$deviance` | `r summary(model3.pre.sa)$df.residual` | `r pchisq(summary(model3.pre.sa)$deviance, summary(model3.pre.sa)$df.residual, lower.tail=FALSE)` |
| Model 4 | `r summary(model4.pre.sa)$deviance` | `r summary(model4.pre.sa)$df.residual` | `r pchisq(summary(model4.pre.sa)$deviance, summary(model4.pre.sa)$df.residual, lower.tail=FALSE)` |
  
$H_0$ is rejected for all models.

  
**post-COVID**  

| Model | Deviance | df | p-value |
|:-:|:-:|:-:|:-:|
| Model 1 | `r summary(model1.post.sa)$deviance` | `r summary(model1.post.sa)$df.residual` | `r pchisq(summary(model1.post.sa)$deviance, summary(model1.post.sa)$df.residual, lower.tail=FALSE)` | 
| Model 2 | `r summary(model2.post.sa)$deviance` | `r summary(model2.post.sa)$df.residual` | `r pchisq(summary(model2.post.sa)$deviance, summary(model2.post.sa)$df.residual, lower.tail=FALSE)` |
| Model 3 | `r summary(model3.post.sa)$deviance` | `r summary(model3.post.sa)$df.residual` | `r pchisq(summary(model3.post.sa)$deviance, summary(model3.post.sa)$df.residual, lower.tail=FALSE)` |
| Model 4 | `r summary(model4.post.sa)$deviance` | `r summary(model4.post.sa)$df.residual` | `r pchisq(summary(model4.post.sa)$deviance, summary(model4.post.sa)$df.residual, lower.tail=FALSE)` |
  
For Model 4, $H_0$ is not rejected.  

### AIC and BIC
Each model's AIC and BIC was as follows.  

**pre-COVID**  
  
Model 5 is the best in terms of both AIC and BIC
  
| Model | AIC | BIC |
|:-:|:-:|:-:|
| Model 1 | `r AIC(model1.pre.sa)` |`r BIC(model1.pre.sa)` |
| Model 2 | `r AIC(model2.pre.sa)` |`r BIC(model2.pre.sa)` |
| Model 3 | `r AIC(model3.pre.sa)` |`r BIC(model3.pre.sa)` |
| Model 4 | `r AIC(model4.pre.sa)` |`r BIC(model4.pre.sa)` |
| Model 5 | `r AIC(model5.pre.sa)` |`r BIC(model5.pre.sa)` |

**post-COVID**  
  
Model 4 is the best in terms of both AIC and BIC.
  
| Model | AIC | BIC |
|:-:|:-:|:-:|
| Model 1 | `r AIC(model1.post.sa)` |`r BIC(model1.post.sa)` |
| Model 2 | `r AIC(model2.post.sa)` |`r BIC(model2.post.sa)` |
| Model 3 | `r AIC(model3.post.sa)` |`r BIC(model3.post.sa)` |
| Model 4 | `r AIC(model4.post.sa)` |`r BIC(model4.post.sa)` |
| Model 5 | `r AIC(model5.post.sa)` |`r BIC(model5.post.sa)` |

### Best Model  
Saturated model is the best for pre-COVID model. On the other hand, Independence model is the best for post-COVID model. 
  
#### Parameters  
**pre-COVID**  

Although the best model is the saturated model, almost all interaction terms are not significant. The interaction between "5D" and "weekend" is significant and has a negative value. This means the count of "Simple Assault" in 5D on weekend is fewer than the other districts.

```{r}
# Showing the parameters and p-values of the best model for pre-COVID
xkabledply(model5.pre.sa)
```


```{r}
# This function is for creating graphs showing estimated parameters and their CIs
# The funcitons takes 3 arguments: model - fitted model, cl - confidence level, title_str - the string for the title

createCIgraph <- function(model, cl, title_str){
  ci <- confint(model, level = cl)
  lb <- vector()
  ub <- vector()
  for(i in 1:(length(ci)/2)){
    lb = append(lb, ci[i,1])
    ub = append(ub, ci[i,2])
  }
  
  coef_label <- labels(coef(model))
  est <- data.frame(coeff_v = coef(model),
                    LB = lb,
                    UB = ub, 
                    var_name = coef_label)
  
  ggplot(est, aes(x = var_name, y = coeff_v)) +
    geom_point() +
    geom_errorbar(aes(ymin = lb, ymax = ub), width = 0.1) +
    geom_hline(yintercept = 0, lty = 1, color = "red") +
    theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
    scale_x_discrete(limits=coef_label) + 
    xlab("") +
    ylab("Estimated Parameter Value") + 
    ggtitle(title_str)
}
```

```{r}
# Showing the parameters and CIs of the best model of pre-COVID
createCIgraph(model5.pre.sa, 0.95, "95% Confidence Intervals of each parameter")
```

**post-COVID**  

```{r}
# Showing the parameters and p-values of the best model of post-COVID
xkabledply(model4.post.sa)
```


```{r}
# Showing the parameters and CIs of the best model of post-COVID
createCIgraph(model4.post.sa, 0.95, "95% Confidence Intervals of each parameter")
```


## Traffic Violations
```{r}
DF_preCOVID_TV = subset(DF_preCOVID, Category == 'Traffic Violations')
DF_postCOVID_TV = subset(DF_postCOVID, Category == 'Traffic Violations')
```

```{r}
#This chunk is for creating two-way tables

d1 <- xtabs(Count ~ District + Weekend, data = DF_preCOVID_TV)
d2 <- xtabs(Count ~ District + Weekend, data = DF_postCOVID_TV)

kable(d1, format = "html", align = 'c', caption = 'Two-way table by "District" and "Weekend "(pre-COVID)') %>% 
  kable_styling(bootstrap_options = "hover", full_width = F, position = "float_left")
kable(d2, format = "html", align = 'c', caption = 'Two-way table by "District" and "Weekend" (post-COVID)') %>% 
  kable_styling(bootstrap_options = "hover", full_width = F, position = "center")
```

```{r, include=FALSE}
# models for pre-COVID

model1.pre.tv <- glm(Count ~ 1, data = DF_preCOVID_TV, family = poisson)
model2.pre.tv <- glm(Count ~ District, data = DF_preCOVID_TV, family = poisson)
model3.pre.tv <- glm(Count ~ Weekend, data = DF_preCOVID_TV, family = poisson)
model4.pre.tv <- glm(Count ~ District + Weekend, data = DF_preCOVID_TV, family = poisson)
model5.pre.tv <- glm(Count ~ District * Weekend, data = DF_preCOVID_TV, family = poisson)
```

```{r, include=FALSE}
# models for post-COVID

model1.post.tv <- glm(Count ~ 1, data = DF_postCOVID_TV, family = poisson)
model2.post.tv <- glm(Count ~ District, data = DF_postCOVID_TV, family = poisson)
model3.post.tv <- glm(Count ~ Weekend, data = DF_postCOVID_TV, family = poisson)
model4.post.tv <- glm(Count ~ District + Weekend, data = DF_postCOVID_TV, family = poisson)
model5.post.tv <- glm(Count ~ District * Weekend, data = DF_postCOVID_TV, family = poisson)
```

### Deviance  

I tested the below hypothesis at a significance level $\alpha=0.05$:
$$H_0: \ \rm{Reduced \ model \ is \ true.}$$
$$H_1: \ \rm{Satureated \ model \ (Model \ 5) \ is \ true.}$$  


**pre-COVID**  

| Model | Deviance | df | p-value |
|:-:|:-:|:-:|:-:|
| Model 1 | `r summary(model1.pre.tv)$deviance` | `r summary(model1.pre.tv)$df.residual` | `r pchisq(summary(model1.pre.tv)$deviance, summary(model1.pre.tv)$df.residual, lower.tail=FALSE)` | 
| Model 2 | `r summary(model2.pre.tv)$deviance` | `r summary(model2.pre.tv)$df.residual` | `r pchisq(summary(model2.pre.tv)$deviance, summary(model2.pre.tv)$df.residual, lower.tail=FALSE)` |
| Model 3 | `r summary(model3.pre.tv)$deviance` | `r summary(model3.pre.tv)$df.residual` | `r pchisq(summary(model3.pre.tv)$deviance, summary(model3.pre.tv)$df.residual, lower.tail=FALSE)` |
| Model 4 | `r summary(model4.pre.tv)$deviance` | `r summary(model4.pre.tv)$df.residual` | `r pchisq(summary(model4.pre.tv)$deviance, summary(model4.pre.tv)$df.residual, lower.tail=FALSE)` |
  
$H_0$ is not rejected for Model 4.

  
**post-COVID**  

| Model | Deviance | df | p-value |
|:-:|:-:|:-:|:-:|
| Model 1 | `r summary(model1.post.tv)$deviance` | `r summary(model1.post.tv)$df.residual` | `r pchisq(summary(model1.post.tv)$deviance, summary(model1.post.tv)$df.residual, lower.tail=FALSE)` | 
| Model 2 | `r summary(model2.post.tv)$deviance` | `r summary(model2.post.tv)$df.residual` | `r pchisq(summary(model2.post.tv)$deviance, summary(model2.post.tv)$df.residual, lower.tail=FALSE)` |
| Model 3 | `r summary(model3.post.tv)$deviance` | `r summary(model3.post.tv)$df.residual` | `r pchisq(summary(model3.post.tv)$deviance, summary(model3.post.tv)$df.residual, lower.tail=FALSE)` |
| Model 4 | `r summary(model4.post.tv)$deviance` | `r summary(model4.post.tv)$df.residual` | `r pchisq(summary(model4.post.tv)$deviance, summary(model4.post.tv)$df.residual, lower.tail=FALSE)` |
  
$H_0$ is not rejected for Model 4.

### AIC  and BIC
Each model's AIC and BIC was as follows.  

**pre-COVID**  

Model 4 is the best in terms of AIC and BIC.
  
| Model | AIC | BIC |
|:-:|:-:|:-:|
| Model 1 | `r AIC(model1.pre.tv)` |`r BIC(model1.pre.tv)` |
| Model 2 | `r AIC(model2.pre.tv)` |`r BIC(model2.pre.tv)` |
| Model 3 | `r AIC(model3.pre.tv)` |`r BIC(model3.pre.tv)` |
| Model 4 | `r AIC(model4.pre.tv)` |`r BIC(model4.pre.tv)` |
| Model 5 | `r AIC(model5.pre.tv)` |`r BIC(model5.pre.tv)` |

**post-COVID**  

Model 5 is the best in terms of AIC, but Model 4 is the best from BIC. According to Chakrabarti & Ghosh (2011), "The Bayesian Information Criterion (BIC) is more useful in selecting a correct model while the AIC is more appropriate in finding the best model for predicting future observations." I want to select the correct model, not a model with high predictive power, so I will focus on the BIC results.
  
| Model | AIC | BIC |
|:-:|:-:|:-:|
| Model 1 | `r AIC(model1.post.tv)` |`r BIC(model1.post.tv)` |
| Model 2 | `r AIC(model2.post.tv)` |`r BIC(model2.post.tv)` |
| Model 3 | `r AIC(model3.post.tv)` |`r BIC(model3.post.tv)` |
| Model 4 | `r AIC(model4.post.tv)` |`r BIC(model4.post.tv)` |
| Model 5 | `r AIC(model5.post.tv)` |`r BIC(model5.post.tv)` |

### Best Model  
Independence model is the best for pre-COVID and post-COVID. 
  
#### Parameters  
**pre-COVID**  

```{r}
# Showing the parameters, p-values, and CIs of the best model for pre-COVID
xkabledply(model4.pre.tv)
createCIgraph(model4.pre.tv, 0.95, "95% Confidence Intervals of each parameter")
```
  
  
**post-COVID**  

```{r}
# Showing the parameters, p-values, and CIs of the best model for post-COVID
xkabledply(model4.post.tv)
createCIgraph(model4.post.tv, 0.95, "95% Confidence Intervals of each parameter")
```


## Theft
```{r}
DF_preCOVID_Th = subset(DF_preCOVID, Category == 'Theft')
DF_postCOVID_Th = subset(DF_postCOVID, Category == 'Theft')
```

```{r}
# This chunk is for creating two-way tables

d1 <- xtabs(Count ~ District + Weekend, data = DF_preCOVID_Th)
d2 <- xtabs(Count ~ District + Weekend, data = DF_postCOVID_Th)

kable(d1, format = "html", align = 'c', caption = 'Two-way table by "District" and "Weekend "(pre-COVID)') %>% 
  kable_styling(bootstrap_options = "hover", full_width = F, position = "float_left")
kable(d2, format = "html", align = 'c', caption = 'Two-way table by "District" and "Weekend" (post-COVID)') %>% 
  kable_styling(bootstrap_options = "hover", full_width = F, position = "center")
```


```{r, include=FALSE}
# models for pre-COVID

model1.pre.th <- glm(Count ~ 1, data = DF_preCOVID_Th, family = poisson)
model2.pre.th <- glm(Count ~ District, data = DF_preCOVID_Th, family = poisson)
model3.pre.th <- glm(Count ~ Weekend, data = DF_preCOVID_Th, family = poisson)
model4.pre.th <- glm(Count ~ District + Weekend, data = DF_preCOVID_Th, family = poisson)
model5.pre.th <- glm(Count ~ District * Weekend, data = DF_preCOVID_Th, family = poisson)
```

```{r, include=FALSE}
# models for post-COVID

model1.post.th <- glm(Count ~ 1, data = DF_postCOVID_Th, family = poisson)
model2.post.th <- glm(Count ~ District, data = DF_postCOVID_Th, family = poisson)
model3.post.th <- glm(Count ~ Weekend, data = DF_postCOVID_Th, family = poisson)
model4.post.th <- glm(Count ~ District + Weekend, data = DF_postCOVID_Th, family = poisson)
model5.post.th <- glm(Count ~ District * Weekend, data = DF_postCOVID_Th, family = poisson)
```

### Deviance  

I tested the below hypothesis at a significance level $\alpha=0.05$:
$$H_0: \ \rm{Reduced \ model \ is \ true.}$$
$$H_1: \ \rm{Satureated \ model \ (Model \ 5) \ is \ true.}$$  

**pre-COVID**  

| Model | Deviance | df | p-value |
|:-:|:-:|:-:|:-:|
| Model 1 | `r summary(model1.pre.th)$deviance` | `r summary(model1.pre.th)$df.residual` | `r pchisq(summary(model1.pre.th)$deviance, summary(model1.pre.th)$df.residual, lower.tail=FALSE)` | 
| Model 2 | `r summary(model2.pre.th)$deviance` | `r summary(model2.pre.th)$df.residual` | `r pchisq(summary(model2.pre.th)$deviance, summary(model2.pre.th)$df.residual, lower.tail=FALSE)` |
| Model 3 | `r summary(model3.pre.th)$deviance` | `r summary(model3.pre.th)$df.residual` | `r pchisq(summary(model3.pre.th)$deviance, summary(model3.pre.th)$df.residual, lower.tail=FALSE)` |
| Model 4 | `r summary(model4.pre.th)$deviance` | `r summary(model4.pre.th)$df.residual` | `r pchisq(summary(model4.pre.th)$deviance, summary(model4.pre.th)$df.residual, lower.tail=FALSE)` |
  
$H_0$ is not rejected for Model 4.

  
**post-COVID**  

| Model | Deviance | df | p-value |
|:-:|:-:|:-:|:-:|
| Model 1 | `r summary(model1.post.th)$deviance` | `r summary(model1.post.th)$df.residual` | `r pchisq(summary(model1.post.th)$deviance, summary(model1.post.th)$df.residual, lower.tail=FALSE)` | 
| Model 2 | `r summary(model2.post.th)$deviance` | `r summary(model2.post.th)$df.residual` | `r pchisq(summary(model2.post.th)$deviance, summary(model2.post.th)$df.residual, lower.tail=FALSE)` |
| Model 3 | `r summary(model3.post.th)$deviance` | `r summary(model3.post.th)$df.residual` | `r pchisq(summary(model3.post.th)$deviance, summary(model3.post.th)$df.residual, lower.tail=FALSE)` |
| Model 4 | `r summary(model4.post.th)$deviance` | `r summary(model4.post.th)$df.residual` | `r pchisq(summary(model4.post.th)$deviance, summary(model4.post.th)$df.residual, lower.tail=FALSE)` |
  
$H_0$ is not rejected for Model 4.

### AIC and BIC   
Each model's AIC and BIC was as follows.  

**pre-COVID**  
  
Model 4 is the best in terms of AIC and BIC.
  
| Model | AIC | BIC |
|:-:|:-:|:-:|
| Model 1 | `r AIC(model1.pre.th)` |`r BIC(model1.pre.th)` |
| Model 2 | `r AIC(model2.pre.th)` |`r BIC(model2.pre.th)` |
| Model 3 | `r AIC(model3.pre.th)` |`r BIC(model3.pre.th)` |
| Model 4 | `r AIC(model4.pre.th)` |`r BIC(model4.pre.th)` |
| Model 5 | `r AIC(model5.pre.th)` |`r BIC(model5.pre.th)` |

**post-COVID**  

Model 4 is the best in terms of AIC and BIC.
  
| Model | AIC | BIC |
|:-:|:-:|:-:|
| Model 1 | `r AIC(model1.post.th)` |`r BIC(model1.post.th)` |
| Model 2 | `r AIC(model2.post.th)` |`r BIC(model2.post.th)` |
| Model 3 | `r AIC(model3.post.th)` |`r BIC(model3.post.th)` |
| Model 4 | `r AIC(model4.post.th)` |`r BIC(model4.post.th)` |
| Model 5 | `r AIC(model5.post.th)` |`r BIC(model5.post.th)` |  

### Best Model  

**pre-COVID**  

```{r}
# Showing the parameters, p-values, and CIs of the best model for pre-COVID
xkabledply(model4.pre.th)
createCIgraph(model4.pre.th, 0.95, "95% Confidence Intervals of each parameter")
```
  
**post-COVID**
  
```{r}
# Showing the parameters, p-values, and CIs of the best model for post-COVID
xkabledply(model4.post.th)
createCIgraph(model4.post.th, 0.95, "95% Confidence Intervals of each parameter")
```

# Interpretation  
  
* "Weekend = 1" has a negative parameter in all models. However, this does not mean that there are fewer crimes on weekends than on other weekdays. This is because only Saturdays and Sundays are classified as "Weekend = 1", and the number of days classified as "Weekend = 0" is 2.5 times greater.
* Through pre-COVID and post-COVID, the fact that a district is 2D, 3D, or 4D tends to drive up the number of crimes. This is not surprising since these districts are in the Northwest area, which has a large population.  
* The combination of 5D and "Weekend = 1" has the effect of pushing down the number of "Simple Assault" during post-COVID period. This may be due to the fact that the main tourist areas are in the Northwest District, which attracts more people to this area on weekends than to 5D. The interaction between 5D and "Weekend" may have disappeared because outings were suppressed in all districts after COVID-19 outbreak.  
* Prior to 2019, 5D had the effect of pushing down the number of thefts relative to other districts, but after 2020, 5D has the effect of pushing up the number of thefts relative to other districts.  
  
# Conclusion  

COVID-19 appears to not only reduce the number of crimes, but also change crime trends. In particular, 5D seems to have changed crime trends compared to other districts.

# Refereances  

* 6.3.4 - analysis of deviance and Model Selection: Stat 504. PennState: Statistics Online Courses. (n.d.). Retrieved December 11, 2022, from https://online.stat.psu.edu/stat504/lesson/6/6.3/6.3.4  
* 10: Log-Linear Models: Stat 504. PennState: Statistics Online Courses. (n.d.). Retrieved December 10, 2022, from https://online.stat.psu.edu/stat504/lesson/10  
* Chakrabarti, A., & Ghosh, J. K. (2011). AIC, BIC and recent advances in model selection. Philosophy of statistics, 583-605.
